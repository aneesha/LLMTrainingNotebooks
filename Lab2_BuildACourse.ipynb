{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4w68gwJB3gtN"
      },
      "source": [
        "# Lab 2 - Build a Course\n",
        "\n",
        "Uses an LLM API to make a LiaScript course. Can be considered an AutoCourse maker.\n",
        "\n",
        "- Specify a topic and a few other parameters (i.e. sub-sections to nclude and exclude)\n",
        "- Creates a list of sub sections (or chapters)\n",
        "- Generates the content\n",
        "- Generates appropriate activities eg MCQ's\n",
        "- Adds simplified sections to explain complex things better\n",
        "- Includes external links or readings\n",
        "- Includes code snippets/examples for programming related topics\n",
        "- Saves as a Markdown file for valid [LiaScript](https://liascript.github.io/)\n",
        "\n",
        "\n",
        "Uses the LangChain and the latest LangChain Expression Language (LCEL) syntax."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Htgj6fEB3Ji_"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Enter a few details about the course and your Groq API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "V15z77aE-d6F"
      },
      "outputs": [],
      "source": [
        "\n",
        "topic = 'Cybersecurity Concerns with GenAI'\n",
        "teaching_method = 'Explain concepts is a simple and straight forward manner'\n",
        "no_sub_topics = 5\n",
        "sub_topics_to_include = \"Deep Fakes\"\n",
        "sub_topics_to_not_include = \"\"\n",
        "audience = 'Everybody'\n",
        "no_quiz_questions_in_sub_topic = 5\n",
        "narrator_language = \"Australian Female\"\n",
        "output_filename = 'GenAICybersecurity_Course.md'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "H8cYE0Rs3Vhi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8XBQbatU5YIX"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install -q langchain langchain-groq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXg-GFW0sN0C"
      },
      "source": [
        "## Use LangChain Expression Language to Generate a Course"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlZRArXPicoF",
        "outputId": "fee575ee-cf66-46df-bdc4-aef11b8e60d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Getting Course TOC.\n",
            "- Getting content for each sub section.\n",
            "- Getting creative projects.\n",
            "- Getting quiz questions for each sub section.\n"
          ]
        }
      ],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
        "\n",
        "# Setup the model\n",
        "model = ChatGroq(model_name=\"mixtral-8x7b-32768\")\n",
        "\n",
        "json_output_parser = SimpleJsonOutputParser()\n",
        "string_output_parser = StrOutputParser()\n",
        "\n",
        "# Get TOC sections for the course\n",
        "\n",
        "print(\"- Getting Course TOC.\")\n",
        "\n",
        "# First extract the additional specified sub-sections\n",
        "list_of_additional_sub_sections = sub_topics_to_include.split(';')\n",
        "sub_topics_to_include_text = \" \"\n",
        "if len(list_of_additional_sub_sections) > 0:\n",
        "  sub_topics_to_include_text = \"In the sub sections also please include these: \" + sub_topics_to_include\n",
        "\n",
        "list_of_sub_topics_not_to_incude = sub_topics_to_not_include.split(';')\n",
        "sub_topics_to_not_include_text = \" \"\n",
        "if len(list_of_sub_topics_not_to_incude) > 0:\n",
        "  sub_topics_to_not_include_text = \"Please don't include content on these sub-topics (THIS IS VERY IMPORTANT): \" + sub_topics_to_not_include\n",
        "\n",
        "\n",
        "if teaching_method!=\"\":\n",
        "  teaching_method_to_include_text = \"Use this teaching and writing style: \" + teaching_method\n",
        "\n",
        "\n",
        "act_as_ld_template='''\n",
        "                      Please act as a subject matter expert on the topic of {topic}. You also have learning designer skills and knowledge of markdown and json.\n",
        "                      You know how to design online modules with a deep knowledge of the sections that need to be included for the topic. You can break up the content into chunks, explain concepts so that can easily be understood, write quizzes to test knowledge and write creative learning activities for students.\n",
        "                   '''\n",
        "ask_for_sections_template='''\n",
        "                              Could you please come up with {no_sub_topics} sections for an online module on the topic of {topic} for {audience} in json format?\n",
        "                              {sub_topics_to_include_text}\n",
        "                              {sub_topics_to_not_include_text}\n",
        "                              Here is an example of the format you need to return:\n",
        "                              [{{\"sectionname\": \"The name of the section 1\", \"sectiondescription\": \"The descriptions of the section 1\"}}]\n",
        "                              Note that you must only return the section_name and section_description fields in the json that is returned.\n",
        "                              Please don't return any intro text before or after the json. YOU MUST RETURN ONLY VALID JSON.\n",
        "                          '''\n",
        "\n",
        "toc_prompt = ChatPromptTemplate.from_template(act_as_ld_template + ask_for_sections_template)\n",
        "\n",
        "toc_chain = toc_prompt | model | json_output_parser\n",
        "\n",
        "sections = toc_chain.invoke({\"topic\": topic, \"no_sub_topics\": no_sub_topics, \"sub_topics_to_include_text\": sub_topics_to_include_text, \"sub_topics_to_not_include_text\": sub_topics_to_not_include_text, \"audience\": audience })\n",
        "\n",
        "updated_sections = []\n",
        "for section in sections:\n",
        "  new_section = {\"topic\": topic, \"no_sub_topics\": no_sub_topics, \"sub_topics_to_include_text\": sub_topics_to_include_text, \"sub_topics_to_not_include_text\": sub_topics_to_not_include_text, \"no_quiz_questions_in_sub_topic\":no_quiz_questions_in_sub_topic, \"audience\": audience, \"teaching_method_to_include_text\": teaching_method_to_include_text, \"section_name\": section[\"sectionname\"], \"section_description\": section[\"sectiondescription\"]}\n",
        "  updated_sections.append(new_section)\n",
        "\n",
        "# Get content for each sub section\n",
        "\n",
        "print(\"- Getting content for each sub section.\")\n",
        "\n",
        "section_details_template='''\n",
        "                              Could you please write the content for this section name: {section_name}\n",
        "                              The content must be appropriate for this audience: {audience}\n",
        "                              The description of the topic that you must write is {section_description}.\n",
        "                              {teaching_method_to_include_text}\n",
        "                              {sub_topics_to_not_include_text}\n",
        "                              Please first output the section name as a level 2 markdown eg ## {section_name}\n",
        "                              If the section is on programming or coding please include code examples within backticks and specify the language and filename eg:\n",
        "                              ``` js     +Filename.js\n",
        "                                  let hi = \"Hello World\"\n",
        "                              ```\n",
        "                              If the section needs math just place the Latex for the math equations between $ signs eg $ \\frac{{a}}{{\\sum{{b+i}}}} $\n",
        "                              You can include sub sections. Please place the sub section headings within ** and ** followed by \\n (eg **Goals** \\n ) as this is the markdown for sub sections at heading level 3 and a newline is required after.\n",
        "                              For difficult concept please include a section also \"**Additional Links**\" with links to Wikipedia and please make sure the proper markdown is used for links. Only include links to wikipedia that exist, don't include links to other sites (this is very important).\n",
        "                          '''\n",
        "\n",
        "author_sections_prompt = ChatPromptTemplate.from_template(act_as_ld_template + section_details_template)\n",
        "\n",
        "author_sections_chain = author_sections_prompt | model | string_output_parser\n",
        "\n",
        "sections_markdown = author_sections_chain.batch(updated_sections)\n",
        "\n",
        "# Get creative projects\n",
        "\n",
        "print(\"- Getting creative projects.\")\n",
        "\n",
        "creative_project_template='''\n",
        "                              Could you please come up with a few creative project ideas for {topic} that will be appropriate for {audience}?\n",
        "                              Be creative and the project should assist students in learning higher level skills that can't be obtained by doing multiple choice tests.\n",
        "                              The high level project ideas should develop levels from Blooms taxonomy including Application, Analysis, Synthesis, and Evaluation.\n",
        "                              Please don't output the section name or the type of level used from Blooms taxonomy but do include an introductory paragraph.\n",
        "                              {sub_topics_to_not_include_text}\n",
        "                              If the project for the section is on programming or coding please include code examples for the project within backticks and specify the language and filename eg:\n",
        "                              ``` js     +Filename.js\n",
        "                                  let hi = \"Hello World\"\n",
        "                              ```\n",
        "                              If the project for the section needs maths please place the Latex for the math equations between $ signs eg $ \\frac{{a}}{{\\sum{{b+i}}}} $\n",
        "                              Don't include quiz questions.\n",
        "                              Include each project as a sub sections in markdown. Please place the sub section headings within ** and ** followed by \\n (eg **Project 1** \\n ) as this is the markdown for sub sections at heading level 3 and a newline is required after.\n",
        "                          '''\n",
        "\n",
        "creative_project_prompt = ChatPromptTemplate.from_template(act_as_ld_template + creative_project_template)\n",
        "\n",
        "creative_project_chain = creative_project_prompt | model | string_output_parser\n",
        "\n",
        "creative_projects = creative_project_chain.invoke({\"topic\": topic, \"no_sub_topics\": no_sub_topics, \"sub_topics_to_include_text\": sub_topics_to_include_text, \"sub_topics_to_not_include_text\": sub_topics_to_not_include_text, \"audience\": audience })\n",
        "\n",
        "# Get Quiz Questions for each section\n",
        "\n",
        "print(\"- Getting quiz questions for each sub section.\")\n",
        "\n",
        "section_assessment_template='''\n",
        "                              Could you please write quiz questions for the content in {section_name} that will be appropriate for {audience}?\n",
        "                              The description of the topic that you must write quiz questions for is {section_description}.\n",
        "                              Please write {no_quiz_questions_in_sub_topic} questions in the json format that is given in the example below:\n",
        "\n",
        "                              [\n",
        "                                {{\"question\": \"Question 1\",\n",
        "                                 \"questiontype\": \"singleoption\",\n",
        "                                 \"options\": [{{\"optionname\": \"Option 1\", \"correct\": \"false\"}}, {{\"optionname\": \"Option 2\", \"correct\": \"true\"}}]\n",
        "                                }},\n",
        "                                {{\"question\": \"Question 2\",\n",
        "                                 \"questiontype\": \"multipleoptions\",\n",
        "                                 \"options\": [{{\"optionname\": \"Option 1\", \"correct\": \"false\"}}, {{\"optionname\": \"Option 2\", \"correct\": \"true\"}}, {{\"optionname\": \"Option 3\", \"correct\": \"true\"}}]\n",
        "                                }}\n",
        "                              ]\n",
        "\n",
        "                              The questions must be returned in the same json format as what is given above. The incorrect answers should not be obvious or easy.\n",
        "                              Please note that you there are 2 types of questions namely single_option and multiple_options.\n",
        "                              Only return the JSON and no other before or after text.\n",
        "                          '''\n",
        "\n",
        "assessment_prompt = ChatPromptTemplate.from_template(act_as_ld_template + section_assessment_template)\n",
        "\n",
        "assessment_chain = assessment_prompt | model | json_output_parser\n",
        "\n",
        "quiz_questions = assessment_chain.batch(updated_sections)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWlms8i9dii4",
        "outputId": "34541d60-e2c7-415a-e55e-dd035d62b83c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Convert MCQ Json to Liascript Markdown.\n",
            "- Collating course content.\n"
          ]
        }
      ],
      "source": [
        "# Convert Quiz Json to LiaScript Markdown\n",
        "print(\"- Convert MCQ Json to Liascript Markdown.\")\n",
        "\n",
        "quiz_questions = [[] if x is None else x for x in quiz_questions] # Makes None an empty list\n",
        "\n",
        "course_assessment_markdown = {}\n",
        "\n",
        "for index, quiz_section in enumerate(quiz_questions):\n",
        "  question_markdown = \"\"\n",
        "  #print(quiz_section)\n",
        "  for question in quiz_section:\n",
        "    question_title = question['question']\n",
        "    question_type = question['questiontype']\n",
        "    if (question_type == \"singleoption\"):\n",
        "      open_brace = '('\n",
        "      close_brace = ')'\n",
        "    else:\n",
        "      open_brace = '['\n",
        "      close_brace = ']'\n",
        "    question_markdown += question_title + '\\n\\n'\n",
        "    options = question['options']\n",
        "    for option in options:\n",
        "      option_name = option[\"optionname\"]\n",
        "      if option['correct'] == \"true\":\n",
        "        marker = 'X'\n",
        "      else:\n",
        "        marker = ' '\n",
        "      question_markdown += f'''    [{open_brace}{marker}{close_brace}] {option_name} \\n'''\n",
        "    question_markdown += '\\n'\n",
        "    section_name = sections[index]['sectionname']\n",
        "    course_assessment_markdown[section_name] = question_markdown\n",
        "\n",
        "\n",
        "# Collate course and force download of the Markdown file\n",
        "\n",
        "print(\"- Collating course content.\")\n",
        "\n",
        "course_markdown = \"\"\n",
        "\n",
        "course_markdown += f\"\"\"\n",
        "<!--\n",
        "\n",
        "author:   Course Builder\n",
        "email:    nobody@nowhere.com\n",
        "version:  0.0.2\n",
        "language: en\n",
        "narrator: {narrator_language}\n",
        "\n",
        "logo:     https://liascript.github.io/img/bg-showcase-1.jpg\n",
        "\n",
        "comment:  Eduweaver generates course content using LLMs and outputs in Liascript Markdown\n",
        "\n",
        "-->\n",
        "\"\"\"\n",
        "\n",
        "course_markdown += f'''# {topic}\\n'''\n",
        "\n",
        "# Make the TOC\n",
        "toc = \"In this course the following content will be covered: \\n\\n\"\n",
        "for section in sections:\n",
        "  section_name = section['sectionname']\n",
        "  section_description = section['sectiondescription']\n",
        "  toc += f'''- {section_name} \\n {section_description} \\n\\n'''\n",
        "\n",
        "course_markdown += \"\"\"\n",
        "> This course is completely generated by Eduweaver (using ChatGPT) in Liascript Markdown format.\n",
        "> Please verify the content before publishing the course. \\n \\n\n",
        "\"\"\"\n",
        "\n",
        "course_markdown += toc\n",
        "\n",
        "for index, section in enumerate(sections):\n",
        "  section_name = section['sectionname']\n",
        "  section_description = section['sectiondescription']\n",
        "  section_content = sections_markdown[index]\n",
        "  if section_name in course_assessment_markdown:\n",
        "    section_assessment = course_assessment_markdown[section_name]\n",
        "  else:\n",
        "    section_assessment = None\n",
        "\n",
        "  course_markdown += f'''{section_content}\\n\\n'''\n",
        "  if section_assessment!=None:\n",
        "    course_markdown += f'''### Quiz Questions \\n\\n'''\n",
        "    course_markdown += f'''{section_assessment}\\n'''\n",
        "\n",
        "course_markdown += f'''## Project Ideas \\n\\n'''\n",
        "course_markdown += f'''{creative_projects}\\n\\n'''\n",
        "\n",
        "with open(output_filename, 'w') as writefile:\n",
        "    writefile.write(course_markdown)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sPrnraI2Nei"
      },
      "source": [
        "## What to do next?\n",
        "\n",
        "- Place the markdown (.md) file on github and then view using the [Liascript Viewer](https://liascript.github.io/)\n",
        "OR\n",
        "- Copy the markdown content into the [Liascript LiveEditor](https://liascript.github.io/LiveEditor/) for editing and previewing."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "conda_python3",
      "language": "python",
      "name": "conda_python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
